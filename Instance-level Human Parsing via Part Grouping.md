# Instance-level Human Parsing via Part Grouping Network 

由于缺乏足够的数据资源和在单次传递中解析多个实例的技术难度，对实际人类分析场景的实例级人工解析仍未得到充分研究。几个相关的工作都遵循“通过检测解析”的pipeline，这种流程严重依赖于单独训练的检测模型来定位实例，然后顺序地为每个实例执行人工解析。尽管如此，检测和解析的两个不同的优化目标导致次优表示学习和最终结果的错误累积。在这项工作中，我们首次尝试探索无检测的局部分组网络（PGN），以便在一次通过中有效地解析图像中的多个人。我们的PGN将实例级人类解析重新定义为两个可以通过统一网络共同学习和相互提炼的孪生子任务：1）语义部分分割，用于将每个像素分配为人类部分（例如，面部，手臂）; 2）实例感知边缘检测，以将语义部分分组到不同的人实例中。因此，共享中间表示将赋予表征细粒度部分和推断每个部分的实例所有物的能力。最后，使用简单的实例分区过程在推理期间获得最终结果。我们在PASCAL-Person-Part数据集上进行了实验，我们的PGN优于所有最先进的方法。此外，我们展示了其在新收集的多人解析数据集（CIHP）上的优势，包括38,280种不同的图像，这是迄今为止最大的数据集，可以促进更高级的人体分析。 CIHP基准和我们的源代码可在http://sysu-hcp.net/lip/上找到。

完全卷积网络（FCN）方法仅关注简化和有限条件下的单人解析任务，例如具有直立姿势和各种日常图像的时尚图片[41,8,18,23,6][11]，并忽视更多 真实世界中多个人物实例出现在一个图像中的情况。 这种不适定的单人解析任务严重地阻止了人类分析对更具挑战性的场景（例如，群体行为预测）的潜在应用。 

在这项工作中，我们的目标是解决更具挑战性的实例级人工解析任务，它不仅需要对各个身体部位或衣服进行分割，还需要将每个部分与一个实例相关联，如图1所示。除了单人解析要面临的困难之外（例如，各种外观/视点，自遮挡），实例级人体解析被认为是一项更具挑战性的任务，由于图像中的人物实例的数量变化很大，使用具有固定预测空间的传统单人解析流水线来传统地解决这种情况，该预测空间对固定数量的部分标签进行分类。

本文从一个新的角度重新构造实例级人体解析，即通过统一网络解决两个连贯的分割聚类任务，包括部分级像素分组和实例级部分分组。 首先，part-level pixel-grouping可以通过语义部分分割任务来解决，该任务将每个像素分配为一个部分标签，其学习分类属性。 其次，给定一组独立的语义部分，实例级部分分组可以根据预测的实例感知边缘确定所有部分的实例所有物，其中由实例边缘分隔的部分将被分组为不同的人物实例。 我们将这种无检测的统一网络称为联合优化语义部分分割和实例感知边缘检测，如图4所示的部分分组网络（PGN）。

![1556874230772](http://pqz0lv0o0.bkt.clouddn.com/1556874230772.png)

### PGN

所提出的部分分组网络（PGN）在单一网络中联合训练和重新进行语义部分分割和实例感知边缘检测。 从技术上讲，这两个子任务都是像素级别分类问题，完全卷积网络（FCN）[29]在这方面表现良好。PGN基于FCN结构构建，其首先使用共享中间层学习共同表示，然后在语义部分分割和边缘检测方面附加两个并行分支。 为了探索和利用这两个任务的语义相关性，进一步结合了一个改进分支，通过利用互补的上下文信息，使两个目标相互有利于彼此。 最后，使用启发式分组算法的有效分区过程可以使用通过联合扫描生成的语义部分分割图和实例感知边缘图获得的线段上的广度搜索来生成实例级人类解析结果。

#### 

#### PGN architecture

- Backbone sub-network

  使用ResNet-101和Deeplab v2作为encoder，语义分割和边缘检测的耦合问题共享几个共享卷积层可以有效学习的关键属性。 直观地，他们都希望根据来自附近像素的低级语境提示和高级语义信息来满足密集识别以便更好地定位。 通过这种方式，我们不是训练两个独立的网络来处理这两个任务，而是执行单个骨干网络，允许权重共享以学习共同的特征表示。

  然而，在最初的Deeplab-v2架构[3]中，输入图像被两个不同的比率（0.75和0.5）下采样，以产生三种不同分辨率的多尺度输入，这些输入由ResNet-101独立处理 共享权重。 然后对输出特征图进行上采样，并通过采用元素最大值进行组合。 这种多尺度方案需要**大量内存并且非常耗时**。 这里，我们使用单一尺度输入，并使用两个更有效和强大的coarse-to-ne schemes.。 首先，受到skip architecture的启发，它将来自深层粗糙层的语义信息与来自浅层网络的外观信息相结合来产生精准的分割。

  我们将ResNet-101的最后三个块的激活连接为最终提取的特征图。辛亏有atrous卷积，这种信息组合允许网络在没有上采样操作的情况下通过全局结构进行本地预测。 其次，在PSPNet [44]通过不同的基于区域的上下文聚合利用全局上下文信息的能力之后，我们在最终分类层之前的提取的特征映射之上使用金字塔池模块。 提取的特征图与四种不同的内核大小进行平均合并，给出了四个空间分辨率分别为1x1,2x2,3x3和6x6的特征映射。 每个特征图在相互连接之前经历卷积和上采样。 从这两种粗略的方案中获益，骨干子网络能够捕获具有不同尺度的上下文信息，并在不同的子系统之间变化。

- Semantic part segmentation branch

  语义分割的常用技术[5,3]是用共享的网络权重预测几个不同尺度的图像，然后将预测与学习的注意力权重相结合。 为了增强我们的统一网络的效率和泛化能力，丢弃多尺度输入，我们应用另一种具有各种平均池化内核大小的上下文聚合模式，这在[44]中引入。 我们附加一侧分支以执行像素方式识别，以便为每个像素分配一个语义部分标签。 11个卷积分类器输出K个通道，对应于包括背景类的目标部件标签的数量。

- Instance-aware edge detection branch

  在[40]之后，我们将边缘检测的侧输出连接到ResNet-101的最后三个块。 在每个侧输出层施加深度监督以学习用于边缘预测的丰富的层次表示。 特别地，我们使用ASPP用于三个边缘侧输出层，以在多个尺度上稳健地检测边界。 我们使用的ASPP包括一个1x1卷积和四个3x3个atrous卷积，扩张率为2,4,8和16.在用于边缘检测的最终分类层中，我们使用金字塔池模块来收集更多的全局信息 更好的推理。 我们对所有边缘输出应用11个卷积层和一个通道来生成边缘得分图。

  [40]：Holistically-Nested Edge Detection
  ![img](https://img-blog.csdn.net/20180710221402378?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JleW9uZGp2NjEw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) 

  （a）Multi-stream learning 示意图，可以看到图中的平行的网络下，每个网络通过不同参数与receptive field大小的不同，获得多尺度的结果。输入影像是同时进入多个网络处理，得到的特征结果直接反应多尺度。

  （b）Skip-layer network learning 示意图，该方法主要连接各个单的初始网络流得到特征响应，并将响应结合在一起输出。

  这里（a）和（b）都是使用一个输出的loss函数进行单一的回归预测，而边缘检测可能通过多个回归预测得到结合的边缘图效果更好。

  （c）Single model on multiple inputs 示意图，单一网络，图像resize方法得到多尺度进行输入，该方法在训练和test过程均可加入。同时在非深度学习中也有广泛应用。

  （d）Training independent networks ，从（a）演化来，通过多个独立网络分别对不同深度和输出loss进行多尺度预测，该方法下训练样本量较大。

  （e）Holistically-nested networks，本文提出的算法结构，从（d）演化来，类似地是一个相互独立多网络多尺度预测系统，但是将multiple side outputs组合成一个单一深度网络。

  作者提出来的方法，对于一个输入，经过连续的卷积层，将每一层的结果保存下来进行ensemble得到第一个输出，同时将每一层的结果concatenate在一起再过一个卷积核得到第二个输出，最后将两个输出在ensemble在一起得到最后的结果。 

  考虑到边缘的pixel个数很少，所以数据的类别不平衡十分严重，作者采用了加权的cross-entropy作为损失函数。 

  ![img](https://img-blog.csdn.net/20180710222223101?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JleW9uZGp2NjEw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) 

  这里beta作为损失函数的权重，其利用正负样本在总样本的权重来作为损失函数的权重。optimize过程为： ![img](https://img-blog.csdn.net/20180710222450135?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JleW9uZGp2NjEw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) 

  这里W代表主干网络的参数，w则是将不同层的结果进行upsample对应的网络参数，b则是将不同层的结果concatenate在一起然后经过一个卷积得到最后的输出时候的卷积网络的参数。 

  

- Renement branch

  我们设计了一个简单而有效的改进分支，用于联合进行分割和边缘预测。 如图4所示，通过将分割和边缘预测映射到具有额外的1x1卷积的更多数量的通道，将分割和边缘预测集成回特征空间。 重新映射的特征映射与来自分段分支和边缘分支的提取的特征映射组合，这些特征映射被最终馈送到另外两个金字塔池模块中以相互增强分段和边缘结果。

#### Instance partition process

由于语义部分分割和实例感知边缘检测的几个任务能够包含描述实例级人工解析所需的所有信息，因此我们采用简单的实例分区过程在推理期间获得最终结果，将人类部分分组为实例基于边缘引导。整个过程如图5所示。
首先，受[25]中的线解码过程的启发，我们同时扫描由非最大抑制[40]细化的部分分割图和边缘图，以创建水平和垂直线段。要创建水平线，我们沿每行从左向右滑动。直接跳过分割图的背景位置，当我们点击分割的前景标签时，新的线开始。当我们到达边缘点并且新线应该从下一个位置开始时，线终止。我们使用单个数字标记每个新行，因此边缘点可以切割线条并在两个不同的实例之间产生边界。我们执行类似的操作，但从上到下滑动以创建垂直线。
下一步是聚合这两种行来创建实例。我们可以将水平线和垂直线共同视为连接图。相同行中的点可以被认为是连接的，因为它们具有相同的标记号。我们通过广度搜索来遍历连通图，以找到连接的组件。详细地说，当访问一个点时，我们水平和垂直地搜索其连接的邻居，然后将它们推入存储属于相同区域的点的队列中。结果，相同实例的行被分组，并且不同的实例区域被分开。
如果实例内存在错误的边缘点，则这个简单的过程不可避免地会引入错误，从而在实例边界周围的区域产生许多小区域。我们进一步设计了一个分组算法来处理这个问题。重新思考分离的区域，如果区域包含多个语义部分标签并覆盖大区域，则它必须是人物实例。相反，如果一个区域很小并且只包含一个部分分段标签，我们当然可以将其判断为错误分离的区域，然后将其合并到其邻居实例区域。如果区域包含至少两个部分标签并覆盖超过30个像素的区域，我们将该区域视为人物实例，这在我们的实验中效果最佳。
在该实例分区过程之后，可以直接从语义部分分割和实例感知边缘映射生成人物实例映射。